{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "skIMW2K7Mk6_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPLw2sV6M7AC",
        "outputId": "66bf767d-57ad-47ef-9aa2-4bef6cb20f01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextSummarizer:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        words = word_tokenize(text.lower())\n",
        "        words = [self.stemmer.stem(word) for word in words if word not in self.stop_words]\n",
        "        return words\n",
        "\n",
        "    def build_similarity_matrix(self, sentences):\n",
        "        similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "        for i in range(len(sentences)):\n",
        "            for j in range(len(sentences)):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                words_i = self.preprocess_text(sentences[i])\n",
        "                words_j = self.preprocess_text(sentences[j])\n",
        "                intersection = len(set(words_i).intersection(set(words_j)))\n",
        "                union = len(set(words_i).union(set(words_j)))\n",
        "                similarity_matrix[i][j] = intersection / union if union != 0 else 0\n",
        "\n",
        "        return similarity_matrix\n",
        "\n",
        "    def summarize(self, text, num_sentences=3):\n",
        "\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "\n",
        "        if len(sentences) <= num_sentences:\n",
        "            return text\n",
        "\n",
        "\n",
        "        similarity_matrix = self.build_similarity_matrix(sentences)\n",
        "\n",
        "        sentence_graph = nx.from_numpy_array(similarity_matrix)\n",
        "\n",
        "        scores = nx.pagerank(sentence_graph)\n",
        "\n",
        "\n",
        "        ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "\n",
        "        top_sentences = [s for score, s in ranked_sentences[:num_sentences]]\n",
        "\n",
        "\n",
        "        summary_sentences = sorted(top_sentences, key=lambda s: sentences.index(s))\n",
        "\n",
        "\n",
        "        summary = ' '.join(summary_sentences)\n",
        "\n",
        "        return summary\n"
      ],
      "metadata": {
        "id": "QM98QYaiNNHW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Text Summarization Tool\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "\n",
        "    sample_text = \"\"\"\n",
        "    Natural language processing (NLP) is a subfield of linguistics, computer science,\n",
        "    and artificial intelligence concerned with the interactions between computers and human language.\n",
        "    It focuses on how to program computers to process and analyze large amounts of natural language data.\n",
        "    The result is a computer capable of understanding the contents of documents, including the contextual\n",
        "    nuances of the language within them. The technology can then accurately extract information and insights\n",
        "    contained in the documents as well as categorize and organize the documents themselves.\n",
        "    Challenges in natural language processing frequently involve speech recognition, natural language\n",
        "    understanding, and natural language generation. Modern NLP algorithms are based on machine learning,\n",
        "    especially statistical machine learning. The paradigm of machine learning is different from that of\n",
        "    most prior attempts at language processing. Prior implementations often involved direct hand-coding\n",
        "    of large sets of rules.\n",
        "    \"\"\"\n",
        "\n",
        "    summarizer = TextSummarizer()\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nOptions:\")\n",
        "        print(\"1. Summarize sample text\")\n",
        "        print(\"2. Enter your own text\")\n",
        "        print(\"3. Read text from file\")\n",
        "        print(\"4. Exit\")\n",
        "\n",
        "        choice = input(\"Enter your choice (1-4): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            text = sample_text\n",
        "        elif choice == '2':\n",
        "            print(\"Enter your text (press Enter twice to finish):\")\n",
        "            lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if line.strip() == '':\n",
        "                    if len(lines) > 0:\n",
        "                        break\n",
        "                    else:\n",
        "                        continue\n",
        "                lines.append(line)\n",
        "            text = '\\n'.join(lines)\n",
        "        elif choice == '3':\n",
        "            filename = input(\"Enter filename: \")\n",
        "            try:\n",
        "                with open(filename, 'r', encoding='utf-8') as file:\n",
        "                    text = file.read()\n",
        "            except FileNotFoundError:\n",
        "                print(\"File not found. Please try again.\")\n",
        "                continue\n",
        "        elif choice == '4':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "            continue\n",
        "\n",
        "        num_sentences = int(input(\"How many sentences should the summary contain? \"))\n",
        "\n",
        "        summary = summarizer.summarize(text, num_sentences)\n",
        "\n",
        "        print(\"\\nOriginal Text Length:\", len(text), \"characters\")\n",
        "        print(\"Summary Length:\", len(summary), \"characters\")\n",
        "        print(\"\\nSummary:\")\n",
        "        print(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0cbmUPZNau8",
        "outputId": "70acd53f-4127-4ad5-ae90-1ae7e861f1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Summarization Tool\n",
            "-----------------------\n",
            "\n",
            "Options:\n",
            "1. Summarize sample text\n",
            "2. Enter your own text\n",
            "3. Read text from file\n",
            "4. Exit\n",
            "Enter your choice (1-4): 2\n",
            "Enter your text (press Enter twice to finish):\n",
            "Natural language processing (NLP) is a subfield of linguistics, computer science,      and artificial intelligence concerned with the interactions between computers and human language.      It focuses on how to program computers to process and analyze large amounts of natural language data.      The result is a computer capable of understanding the contents of documents, including the contextual      nuances of the language within them. The technology can then accurately extract information and insights      contained in the documents as well as categorize and organize the documents themselves.      Challenges in natural language processing frequently involve speech recognition, natural language      understanding, and natural language generation. Modern NLP algorithms are based on machine learning,      especially statistical machine learning. The paradigm of machine learning is different from that of      most prior attempts at language processing. Prior implementations often involved direct hand-coding      of large sets of rules.\n"
          ]
        }
      ]
    }
  ]
}